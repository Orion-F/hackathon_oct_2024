{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5808df077715eb",
   "metadata": {},
   "source": [
    "# AIM Hackathon: Sample code\n",
    "19.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bec73e3a0cd2571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:42:29.779608Z",
     "start_time": "2024-10-18T08:42:26.029795Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings.base import OpenAIEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# load openai key\n",
    "if not load_dotenv():\n",
    "    raise Exception('Error loading .env file. Make sure to place a valid OPEN_AI_KEY in the .env file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ca3544d9e60a0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:34.765879Z",
     "start_time": "2024-10-18T08:45:34.751838Z"
    }
   },
   "outputs": [],
   "source": [
    "REPORTS_SAVE_PATH = 'data/sample_reports'\n",
    "DB_PATH = \"data/db/sample.db\"\n",
    "\n",
    "# See https://openai.com/api/pricing/\n",
    "MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "884c8d201075524d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:35.123394Z",
     "start_time": "2024-10-18T08:45:35.064870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>year</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pdf_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2023</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2021</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2019</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2023</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://sustainability.aboutamazon.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2021</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://sustainability.aboutamazon.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tarkett</td>\n",
       "      <td>2020</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://www.tarkett.com/sites/default/files/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>trivium-packaging</td>\n",
       "      <td>2021</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://www.triviumpackaging.com/media/13fl4q3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>trivium-packaging</td>\n",
       "      <td>2020</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://triviumpackaging.com/sustainability/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>trust</td>\n",
       "      <td>2023</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://dezlwerqy1h00.cloudfront.net/images/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>trust</td>\n",
       "      <td>2021</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://dezlwerqy1h00.cloudfront.net/images/co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company_name  year      dataset  \\\n",
       "0              Walmart  2023  handcrafted   \n",
       "1              Walmart  2021  handcrafted   \n",
       "2              Walmart  2019  handcrafted   \n",
       "3               Amazon  2023  handcrafted   \n",
       "4               Amazon  2021  handcrafted   \n",
       "..                 ...   ...          ...   \n",
       "141            tarkett  2020      scraped   \n",
       "142  trivium-packaging  2021      scraped   \n",
       "143  trivium-packaging  2020      scraped   \n",
       "144              trust  2023      scraped   \n",
       "145              trust  2021      scraped   \n",
       "\n",
       "                                               pdf_url  \n",
       "0    https://corporate.walmart.com/content/dam/corp...  \n",
       "1    https://corporate.walmart.com/content/dam/corp...  \n",
       "2    https://corporate.walmart.com/content/dam/corp...  \n",
       "3    https://sustainability.aboutamazon.com/content...  \n",
       "4    https://sustainability.aboutamazon.com/content...  \n",
       "..                                                 ...  \n",
       "141  https://www.tarkett.com/sites/default/files/20...  \n",
       "142  https://www.triviumpackaging.com/media/13fl4q3...  \n",
       "143  https://triviumpackaging.com/sustainability/re...  \n",
       "144  https://dezlwerqy1h00.cloudfront.net/images/co...  \n",
       "145  https://dezlwerqy1h00.cloudfront.net/images/co...  \n",
       "\n",
       "[146 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/reports.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b3873627faac",
   "metadata": {},
   "source": [
    "## Download some reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7016c71d2e6c157c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:36.892663Z",
     "start_time": "2024-10-18T08:45:36.882663Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXAMPLE: select apple reports\n",
    "df_sample = df[df['company_name'] == 'Apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f11fde1d1812112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:37.365944Z",
     "start_time": "2024-10-18T08:45:37.344942Z"
    }
   },
   "outputs": [],
   "source": [
    "# download Apple reports to save_dir\n",
    "def download_files(df: pd.DataFrame, save_dir: str):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for url in df['pdf_url']:\n",
    "        pdf_filename = os.path.basename(url)\n",
    "        response = requests.get(url)\n",
    "        with open(os.path.join(save_dir, pdf_filename), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    print(f\"Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb4a2407fec641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "download_files(df_sample, REPORTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93afeb4f8e422c6",
   "metadata": {},
   "source": [
    "## Create simple vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42eeec6e365fd353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:58.246571Z",
     "start_time": "2024-10-18T08:45:58.230622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load PDFs\n",
    "def get_documents_from_path(files_path: str) -> [Document]:\n",
    "    documents = []\n",
    "    \n",
    "    for file in os.listdir(files_path):\n",
    "        _, file_extension = os.path.splitext(file)\n",
    "        text = \"\"\n",
    "        \n",
    "        if file_extension == \".pdf\":\n",
    "            with open(os.path.join(files_path, file), 'rb') as f:\n",
    "                reader = PyPDF2.PdfReader(f, strict=False)\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "                \n",
    "            if text:\n",
    "                documents.append(Document(page_content=text, metadata={\"source\": file}))\n",
    "            else:\n",
    "                print(f\"WARNING: No text extracted from {file}\")\n",
    "        else:\n",
    "            # TODO: can add support for other file types here\n",
    "            raise Exception(f\"Unsupported file extension: {file_extension}\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0705d007aae0741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:46:27.182748Z",
     "start_time": "2024-10-18T08:45:58.503064Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = get_documents_from_path(REPORTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bc507f61c0167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO could also just provide a dummy retriever to not spoil too much\n",
    "class DummyRetriever:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "    def dummy_retriever(self, query):\n",
    "        import random\n",
    "        return random.sample(self.texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6af1ec858814862b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:46:39.300669Z",
     "start_time": "2024-10-18T08:46:27.184677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 202599\n"
     ]
    }
   ],
   "source": [
    "# Create database\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300, separators=[\"\\n\\n\", \"\\n\"])\n",
    "\n",
    "# split documents and create vector database\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()  # https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# count build embedding token number\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "build_token_count = sum([len(tokenizer.encode(doc.page_content)) for doc in texts])\n",
    "print(f\"Token count: {build_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fba814c7f46c5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the database\n",
    "with open(DB_PATH, \"wb\") as f:\n",
    "    pickle.dump(db.serialize_to_bytes(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2816a3db31f23fa",
   "metadata": {},
   "source": [
    "## Create simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58dd89c06d4a0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database\n",
    "DB_PATH = \"data/db/sample.db\"\n",
    "\n",
    "with open(DB_PATH, \"rb\") as f:\n",
    "    db_bytes = pickle.load(f)\n",
    "    db = FAISS.deserialize_from_bytes(db_bytes, OpenAIEmbeddings(), allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea269a7277b80cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:57:54.879740Z",
     "start_time": "2024-10-18T08:57:54.176727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "llm = ChatOpenAI(model_name=MODEL, temperature=0)  # for deterministic outputs\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert assistant. Use only the following retrieved context to answer the question accurately and concisely. \n",
    "If nothing is mentioned in the context, say \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], \n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f822aca82b51ffa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:57:55.486968Z",
     "start_time": "2024-10-18T08:57:55.479646Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    response = retrieval_chain({\"query\": query})\n",
    "    print(f\"Question: {query}\\nAnswer: {response['result']}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8739e93ca8e92503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:57:57.528950Z",
     "start_time": "2024-10-18T08:57:55.868325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oforo\\AppData\\Local\\Temp\\ipykernel_23540\\719201039.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = retrieval_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When does Apply try to achieve carbon neutrality?\n",
      "Answer: Apple aims to achieve carbon neutrality for its entire carbon footprint, including products, by 2030.\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"When does Apply try to achieve carbon neutrality?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad696ce943161049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does Apple comply with EU Climate Law: Binding goal for zero emissions by 2050. Please rate using the following criteria: Ideal Output (70-100 Best ESG Compliance) is Full transition to renewable energy; zero-emission operations by 2050. Medium Output (40-60 Moderate ESG Compliance) is Significant emission reductions but reliance on offset schemes. Worst Output (0-30 Poor ESG Compliance) is Limited action with minimal emission reductions\n",
      "Answer: Apple's goal to achieve carbon neutrality for its entire carbon footprint, including products, by 2030, reducing related emissions by 75 percent compared with 2015, aligns with the EU Climate Law's binding goal for zero emissions by 2050. This indicates a high level of ESG compliance, with an Ideal Output rating of 70-100.\n"
     ]
    }
   ],
   "source": [
    "res = ask_question(\"Does Apple comply with EU Climate Law: Binding goal for zero emissions by 2050. Please rate using the following criteria: Ideal Output (70-100 Best ESG Compliance) is Full transition to renewable energy; zero-emission operations by 2050. Medium Output (40-60 Moderate ESG Compliance) is Significant emission reductions but reliance on offset schemes. Worst Output (0-30 Poor ESG Compliance) is Limited action with minimal emission reductions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
